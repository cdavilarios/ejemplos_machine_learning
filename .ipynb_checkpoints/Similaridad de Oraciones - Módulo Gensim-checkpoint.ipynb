{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando el módulo de Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enrique\\PycharmProjects\\EV_DEEP_LEARNING\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    'real solido de atun en aceite x 170 gr',  # doc_id 0\n",
    "    'a-1 filete atun aceite 3 x 80 gr',  # doc_id 1\n",
    "    'a-1 filete de atun en aceite x 170 gr',  # doc_id 2\n",
    "    'a-1 grated de atun en aceite x 170 gr',  # doc_id 3\n",
    "    'a-1 lomito atun aceite x 170 g',  # doc_id 4\n",
    "    'real sólido de atún en aceite vegetal. lata 170gr',  # doc_id 5\n",
    "    'a1 ver todos sólido de atún en aceite vegetal lata x170gr', # doc_id 6\n",
    "    'fanny sólido de atún en aceite vegetal lata 170 g', # doc_id 7\n",
    "    'fanny solido de atun en aceite vegetal x 170 gr', # doc_id 8\n",
    "    'real solido de atun en aceite oliva x 170 gr', # doc_id 9\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['real', 'solido', 'atun', 'aceite', 'x', '170', 'gr'], ['a-1', 'filete', 'atun', 'aceite', '3', 'x', '80', 'gr'], ['a-1', 'filete', 'atun', 'aceite', 'x', '170', 'gr'], ['a-1', 'grated', 'atun', 'aceite', 'x', '170', 'gr'], ['a-1', 'lomito', 'atun', 'aceite', 'x', '170', 'g'], ['real', 's\\xc3\\xb3lido', 'at\\xc3\\xban', 'aceite', 'vegetal.', 'lata', '170gr'], ['a1', 'ver', 'todos', 's\\xc3\\xb3lido', 'at\\xc3\\xban', 'aceite', 'vegetal', 'lata', 'x170gr'], ['fanny', 's\\xc3\\xb3lido', 'at\\xc3\\xban', 'aceite', 'vegetal', 'lata', '170', 'g'], ['fanny', 'solido', 'atun', 'aceite', 'vegetal', 'x', '170', 'gr'], ['real', 'solido', 'atun', 'aceite', 'oliva', 'x', '170', 'gr']]\n"
     ]
    }
   ],
   "source": [
    "stoplist = set(['la', 'en','de'])\n",
    "\n",
    "texts = [[word.lower() for word in document.split()\n",
    "          if word.lower() not in stoplist]\n",
    "         for document in documents]\n",
    "\n",
    "print texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'gr': 6, '80': 1, '170': 7, 'ver': 1, 'filete': 2, '170gr': 1, '3': 1, 'lata': 3, 'grated': 1, 'atun': 7, 'vegetal.': 1, 'fanny': 2, 'todos': 1, 'x170gr': 1, 'real': 3, 's\\xc3\\xb3lido': 3, 'a1': 1, 'aceite': 10, 'at\\xc3\\xban': 3, 'a-1': 4, 'vegetal': 3, 'oliva': 1, 'g': 2, 'solido': 3, 'lomito': 1, 'x': 7})\n"
     ]
    }
   ],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "print frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['real', 'solido', 'atun', 'aceite', 'x', '170', 'gr'], ['a-1', 'filete', 'atun', 'aceite', 'x', 'gr'], ['a-1', 'filete', 'atun', 'aceite', 'x', '170', 'gr'], ['a-1', 'atun', 'aceite', 'x', '170', 'gr'], ['a-1', 'atun', 'aceite', 'x', '170', 'g'], ['real', 's\\xc3\\xb3lido', 'at\\xc3\\xban', 'aceite', 'lata'], ['s\\xc3\\xb3lido', 'at\\xc3\\xban', 'aceite', 'vegetal', 'lata'], ['fanny', 's\\xc3\\xb3lido', 'at\\xc3\\xban', 'aceite', 'vegetal', 'lata', '170', 'g'], ['fanny', 'solido', 'atun', 'aceite', 'vegetal', 'x', '170', 'gr'], ['real', 'solido', 'atun', 'aceite', 'x', '170', 'gr']]\n"
     ]
    }
   ],
   "source": [
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "print texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.corpora.dictionary.Dictionary'>\n",
      "Dictionary(15 unique tokens: [u'real', u's\\xf3lido', u'gr', u'g', u'filete']...)\n"
     ]
    }
   ],
   "source": [
    "#This module implements the concept of Dictionary – a mapping between words and their integer ids\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print type(dictionary)\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(1, 1), (3, 1), (4, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)], [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (9, 1)], [(0, 1), (3, 1), (10, 1), (11, 1), (12, 1)], [(3, 1), (10, 1), (11, 1), (12, 1), (13, 1)], [(3, 1), (6, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)], [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (13, 1), (14, 1)], [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# doc2bow counts the number of occurences of each distinct word,\n",
    "# converts the word to its integer word id and returns the result\n",
    "# as a sparse vector\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LsiModel(num_terms=15, num_topics=2, decay=1.0, chunksize=20000)\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "print lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 1), (5, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"real solido de atun en aceite x 170 gr\" \n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "print vec_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 0.99994826), (0, 0.99736017), (9, 0.99736017), (8, 0.99396342), (3, 0.98814189), (2, 0.98311067), (1, 0.97171909), (7, 0.45667768), (5, 0.38584575), (6, 0.32286653)]\n"
     ]
    }
   ],
   "source": [
    "# convert the query to LSI space\n",
    "vec_lsi = lsi[vec_bow]\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "\n",
    "# perform a similarity query against the corpus\n",
    "sims = index[vec_lsi]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "\n",
    "print sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
